{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ============================================= [ setting ] ==========================================================\n",
    "import pandas as pd  # 데이터 분석 라이브러리\n",
    "import numpy as np  # 계산 라이브러리\n",
    "from tqdm import tqdm  # 진행바\n",
    "from sklearn.metrics import roc_auc_score  # AUC 스코어 계산\n",
    "from sklearn.model_selection import KFold  # K-fold CV\n",
    "from bayes_opt import BayesianOptimization  # 베이지안 최적화 라이브러리\n",
    "from functools import partial  # 함수 변수 고정\n",
    "import lightgbm as lgb  # LightGBM 라이브러리\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_train = pd.read_csv(\"/Users/gimjiseong/Downloads/[ DACON ] Game_Behavior_DataAnalysis_Comp./tidy_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tidy_train.iloc[:, 0:49]\n",
    "y_train = tidy_train.loc[:, \"winner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.set_index(\"game_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================== [ modeling ] ===========================================================\n",
    "## + [lightGBM modeling ] ==================================\n",
    "def lgb_cv(num_leaves, learning_rate, n_estimators, subsample, colsample_bytree, reg_alpha, reg_lambda,\n",
    "           bagging_fraction, x_data = None, y_data = None, n_splits = 5, output = 'score'):\n",
    "    score = 0\n",
    "    kf = KFold(n_splits = n_splits)\n",
    "    models = []\n",
    "    for train_index, valid_index in kf.split(x_data):\n",
    "        x_train, y_train = x_data.iloc[train_index], y_data[train_index]\n",
    "        x_valid, y_valid = x_data.iloc[valid_index], y_data[valid_index]\n",
    "\n",
    "        model = lgb.LGBMClassifier(\n",
    "            num_leaves = int(num_leaves),\n",
    "            learning_rate = learning_rate,\n",
    "            n_estimators = int(n_estimators),\n",
    "            subsample = np.clip(subsample, 0, 1),\n",
    "            colsample_bytree = np.clip(colsample_bytree, 0, 1),\n",
    "            reg_alpha = reg_alpha,\n",
    "            reg_lambda = reg_lambda,\n",
    "            bagging_fraction = np.clip(bagging_fraction, 0, 1)\n",
    "        )\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "\n",
    "        pred = model.predict_proba(x_valid)[:, 1]\n",
    "        true = y_valid\n",
    "        score += roc_auc_score(true, pred) / n_splits\n",
    "\n",
    "    if output == 'score':\n",
    "        return score\n",
    "    if output == 'model':\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | colsam... | learni... | n_esti... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6566  \u001b[0m | \u001b[0m 0.04872 \u001b[0m | \u001b[0m 0.2891  \u001b[0m | \u001b[0m 0.07212 \u001b[0m | \u001b[0m 37.79   \u001b[0m | \u001b[0m 223.6   \u001b[0m | \u001b[0m 0.5077  \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.6639  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6698  \u001b[0m | \u001b[95m 0.3081  \u001b[0m | \u001b[95m 0.5836  \u001b[0m | \u001b[95m 0.00705 \u001b[0m | \u001b[95m 890.3   \u001b[0m | \u001b[95m 150.3   \u001b[0m | \u001b[95m 1.781   \u001b[0m | \u001b[95m 24.8    \u001b[0m | \u001b[95m 0.8637  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.656   \u001b[0m | \u001b[0m 0.7589  \u001b[0m | \u001b[0m 0.9705  \u001b[0m | \u001b[0m 0.07595 \u001b[0m | \u001b[0m 403.3   \u001b[0m | \u001b[0m 428.0   \u001b[0m | \u001b[0m 7.134   \u001b[0m | \u001b[0m 13.53   \u001b[0m | \u001b[0m 0.8541  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6629  \u001b[0m | \u001b[0m 0.9132  \u001b[0m | \u001b[0m 0.7608  \u001b[0m | \u001b[0m 0.05172 \u001b[0m | \u001b[0m 185.2   \u001b[0m | \u001b[0m 317.1   \u001b[0m | \u001b[0m 2.839   \u001b[0m | \u001b[0m 16.36   \u001b[0m | \u001b[0m 0.4601  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6529  \u001b[0m | \u001b[0m 0.5444  \u001b[0m | \u001b[0m 0.2174  \u001b[0m | \u001b[0m 0.08001 \u001b[0m | \u001b[0m 748.5   \u001b[0m | \u001b[0m 872.1   \u001b[0m | \u001b[0m 2.675   \u001b[0m | \u001b[0m 30.74   \u001b[0m | \u001b[0m 0.6528  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6341  \u001b[0m | \u001b[0m 0.3139  \u001b[0m | \u001b[0m 0.1218  \u001b[0m | \u001b[0m 0.006753\u001b[0m | \u001b[0m 27.79   \u001b[0m | \u001b[0m 1.023e+0\u001b[0m | \u001b[0m 8.934   \u001b[0m | \u001b[0m 39.48   \u001b[0m | \u001b[0m 0.01829 \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6654  \u001b[0m | \u001b[0m 0.4298  \u001b[0m | \u001b[0m 0.2828  \u001b[0m | \u001b[0m 0.08845 \u001b[0m | \u001b[0m 466.3   \u001b[0m | \u001b[0m 17.25   \u001b[0m | \u001b[0m 5.28    \u001b[0m | \u001b[0m 44.0    \u001b[0m | \u001b[0m 0.09332 \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6547  \u001b[0m | \u001b[0m 0.6715  \u001b[0m | \u001b[0m 0.9878  \u001b[0m | \u001b[0m 0.03056 \u001b[0m | \u001b[0m 1.015e+0\u001b[0m | \u001b[0m 1.021e+0\u001b[0m | \u001b[0m 4.376   \u001b[0m | \u001b[0m 8.054   \u001b[0m | \u001b[0m 0.6249  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6533  \u001b[0m | \u001b[0m 0.2074  \u001b[0m | \u001b[0m 0.2875  \u001b[0m | \u001b[0m 0.08516 \u001b[0m | \u001b[0m 1.01e+03\u001b[0m | \u001b[0m 500.2   \u001b[0m | \u001b[0m 5.083   \u001b[0m | \u001b[0m 49.5    \u001b[0m | \u001b[0m 0.08119 \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6665  \u001b[0m | \u001b[0m 0.1786  \u001b[0m | \u001b[0m 0.7549  \u001b[0m | \u001b[0m 0.0581  \u001b[0m | \u001b[0m 999.5   \u001b[0m | \u001b[0m 16.57   \u001b[0m | \u001b[0m 8.097   \u001b[0m | \u001b[0m 48.95   \u001b[0m | \u001b[0m 0.1405  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6643  \u001b[0m | \u001b[0m 0.5373  \u001b[0m | \u001b[0m 0.3093  \u001b[0m | \u001b[0m 0.007398\u001b[0m | \u001b[0m 996.1   \u001b[0m | \u001b[0m 17.44   \u001b[0m | \u001b[0m 3.391   \u001b[0m | \u001b[0m 3.68    \u001b[0m | \u001b[0m 0.2177  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6681  \u001b[0m | \u001b[0m 0.04641 \u001b[0m | \u001b[0m 0.7352  \u001b[0m | \u001b[0m 0.01221 \u001b[0m | \u001b[0m 775.8   \u001b[0m | \u001b[0m 32.44   \u001b[0m | \u001b[0m 0.565   \u001b[0m | \u001b[0m 48.31   \u001b[0m | \u001b[0m 0.4037  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6619  \u001b[0m | \u001b[0m 0.01508 \u001b[0m | \u001b[0m 0.9494  \u001b[0m | \u001b[0m 0.03113 \u001b[0m | \u001b[0m 537.5   \u001b[0m | \u001b[0m 1.016e+0\u001b[0m | \u001b[0m 0.9466  \u001b[0m | \u001b[0m 48.75   \u001b[0m | \u001b[0m 0.331   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6588  \u001b[0m | \u001b[0m 0.937   \u001b[0m | \u001b[0m 0.1735  \u001b[0m | \u001b[0m 0.07438 \u001b[0m | \u001b[0m 409.6   \u001b[0m | \u001b[0m 192.3   \u001b[0m | \u001b[0m 0.1388  \u001b[0m | \u001b[0m 47.97   \u001b[0m | \u001b[0m 0.1836  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6618  \u001b[0m | \u001b[0m 0.685   \u001b[0m | \u001b[0m 0.803   \u001b[0m | \u001b[0m 0.03036 \u001b[0m | \u001b[0m 520.9   \u001b[0m | \u001b[0m 1.022e+0\u001b[0m | \u001b[0m 9.779   \u001b[0m | \u001b[0m 1.669   \u001b[0m | \u001b[0m 0.7791  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6488  \u001b[0m | \u001b[0m 0.6696  \u001b[0m | \u001b[0m 0.1582  \u001b[0m | \u001b[0m 0.01224 \u001b[0m | \u001b[0m 204.5   \u001b[0m | \u001b[0m 24.43   \u001b[0m | \u001b[0m 8.133   \u001b[0m | \u001b[0m 4.074   \u001b[0m | \u001b[0m 0.988   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6558  \u001b[0m | \u001b[0m 0.8682  \u001b[0m | \u001b[0m 0.7957  \u001b[0m | \u001b[0m 0.05055 \u001b[0m | \u001b[0m 47.92   \u001b[0m | \u001b[0m 587.2   \u001b[0m | \u001b[0m 8.075   \u001b[0m | \u001b[0m 43.85   \u001b[0m | \u001b[0m 0.3841  \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 0.671   \u001b[0m | \u001b[95m 0.8141  \u001b[0m | \u001b[95m 0.5401  \u001b[0m | \u001b[95m 0.01487 \u001b[0m | \u001b[95m 752.7   \u001b[0m | \u001b[95m 76.95   \u001b[0m | \u001b[95m 9.809   \u001b[0m | \u001b[95m 1.259   \u001b[0m | \u001b[95m 0.1401  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6635  \u001b[0m | \u001b[0m 0.6478  \u001b[0m | \u001b[0m 0.2452  \u001b[0m | \u001b[0m 0.04137 \u001b[0m | \u001b[0m 881.2   \u001b[0m | \u001b[0m 139.1   \u001b[0m | \u001b[0m 9.951   \u001b[0m | \u001b[0m 47.75   \u001b[0m | \u001b[0m 0.02625 \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6592  \u001b[0m | \u001b[0m 0.8903  \u001b[0m | \u001b[0m 0.9882  \u001b[0m | \u001b[0m 0.00328 \u001b[0m | \u001b[0m 596.2   \u001b[0m | \u001b[0m 70.07   \u001b[0m | \u001b[0m 1.726   \u001b[0m | \u001b[0m 0.1232  \u001b[0m | \u001b[0m 0.6315  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6654  \u001b[0m | \u001b[0m 0.1587  \u001b[0m | \u001b[0m 0.9234  \u001b[0m | \u001b[0m 0.02638 \u001b[0m | \u001b[0m 271.8   \u001b[0m | \u001b[0m 827.2   \u001b[0m | \u001b[0m 0.05457 \u001b[0m | \u001b[0m 49.4    \u001b[0m | \u001b[0m 0.0781  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6476  \u001b[0m | \u001b[0m 0.5399  \u001b[0m | \u001b[0m 0.1661  \u001b[0m | \u001b[0m 0.08812 \u001b[0m | \u001b[0m 825.7   \u001b[0m | \u001b[0m 400.4   \u001b[0m | \u001b[0m 5.033   \u001b[0m | \u001b[0m 0.1817  \u001b[0m | \u001b[0m 0.3561  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6493  \u001b[0m | \u001b[0m 0.3299  \u001b[0m | \u001b[0m 0.3444  \u001b[0m | \u001b[0m 0.08379 \u001b[0m | \u001b[0m 1.021e+0\u001b[0m | \u001b[0m 716.9   \u001b[0m | \u001b[0m 1.686   \u001b[0m | \u001b[0m 2.785   \u001b[0m | \u001b[0m 0.1504  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6486  \u001b[0m | \u001b[0m 0.7821  \u001b[0m | \u001b[0m 0.07816 \u001b[0m | \u001b[0m 0.02025 \u001b[0m | \u001b[0m 272.2   \u001b[0m | \u001b[0m 835.5   \u001b[0m | \u001b[0m 1.828   \u001b[0m | \u001b[0m 41.95   \u001b[0m | \u001b[0m 0.1326  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6516  \u001b[0m | \u001b[0m 0.3911  \u001b[0m | \u001b[0m 0.9394  \u001b[0m | \u001b[0m 0.07599 \u001b[0m | \u001b[0m 33.47   \u001b[0m | \u001b[0m 21.5    \u001b[0m | \u001b[0m 8.772   \u001b[0m | \u001b[0m 40.41   \u001b[0m | \u001b[0m 0.925   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6549  \u001b[0m | \u001b[0m 0.2853  \u001b[0m | \u001b[0m 0.1059  \u001b[0m | \u001b[0m 0.017   \u001b[0m | \u001b[0m 476.1   \u001b[0m | \u001b[0m 694.2   \u001b[0m | \u001b[0m 2.172   \u001b[0m | \u001b[0m 48.61   \u001b[0m | \u001b[0m 0.5977  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6557  \u001b[0m | \u001b[0m 0.9226  \u001b[0m | \u001b[0m 0.6354  \u001b[0m | \u001b[0m 0.04279 \u001b[0m | \u001b[0m 785.0   \u001b[0m | \u001b[0m 1.02e+03\u001b[0m | \u001b[0m 1.366   \u001b[0m | \u001b[0m 0.732   \u001b[0m | \u001b[0m 0.04499 \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6389  \u001b[0m | \u001b[0m 0.175   \u001b[0m | \u001b[0m 0.03605 \u001b[0m | \u001b[0m 0.08993 \u001b[0m | \u001b[0m 215.7   \u001b[0m | \u001b[0m 497.3   \u001b[0m | \u001b[0m 1.221   \u001b[0m | \u001b[0m 49.65   \u001b[0m | \u001b[0m 0.4309  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 0.2604  \u001b[0m | \u001b[0m 0.05372 \u001b[0m | \u001b[0m 0.05878 \u001b[0m | \u001b[0m 42.79   \u001b[0m | \u001b[0m 796.3   \u001b[0m | \u001b[0m 1.725   \u001b[0m | \u001b[0m 48.59   \u001b[0m | \u001b[0m 0.4656  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6572  \u001b[0m | \u001b[0m 0.8495  \u001b[0m | \u001b[0m 0.5156  \u001b[0m | \u001b[0m 0.03712 \u001b[0m | \u001b[0m 1.018e+0\u001b[0m | \u001b[0m 290.3   \u001b[0m | \u001b[0m 6.769   \u001b[0m | \u001b[0m 1.628   \u001b[0m | \u001b[0m 0.3787  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.6204  \u001b[0m | \u001b[0m 0.03457 \u001b[0m | \u001b[0m 0.02546 \u001b[0m | \u001b[0m 0.09309 \u001b[0m | \u001b[0m 16.96   \u001b[0m | \u001b[0m 436.9   \u001b[0m | \u001b[0m 7.206   \u001b[0m | \u001b[0m 48.94   \u001b[0m | \u001b[0m 0.06453 \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.6658  \u001b[0m | \u001b[0m 0.06111 \u001b[0m | \u001b[0m 0.9619  \u001b[0m | \u001b[0m 0.0327  \u001b[0m | \u001b[0m 210.1   \u001b[0m | \u001b[0m 1.017e+0\u001b[0m | \u001b[0m 2.004   \u001b[0m | \u001b[0m 49.54   \u001b[0m | \u001b[0m 0.853   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6499  \u001b[0m | \u001b[0m 0.1416  \u001b[0m | \u001b[0m 0.9342  \u001b[0m | \u001b[0m 0.0955  \u001b[0m | \u001b[0m 767.0   \u001b[0m | \u001b[0m 658.1   \u001b[0m | \u001b[0m 1.397   \u001b[0m | \u001b[0m 7.107   \u001b[0m | \u001b[0m 0.6615  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6645  \u001b[0m | \u001b[0m 0.5473  \u001b[0m | \u001b[0m 0.7565  \u001b[0m | \u001b[0m 0.05906 \u001b[0m | \u001b[0m 772.5   \u001b[0m | \u001b[0m 30.26   \u001b[0m | \u001b[0m 3.258   \u001b[0m | \u001b[0m 48.18   \u001b[0m | \u001b[0m 0.9301  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6524  \u001b[0m | \u001b[0m 0.4209  \u001b[0m | \u001b[0m 0.6744  \u001b[0m | \u001b[0m 0.09431 \u001b[0m | \u001b[0m 630.8   \u001b[0m | \u001b[0m 396.9   \u001b[0m | \u001b[0m 2.319   \u001b[0m | \u001b[0m 49.75   \u001b[0m | \u001b[0m 0.1264  \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "func_fixed = partial(lgb_cv, x_data=x_train, y_data=y_train, n_splits = 5, output='score')\n",
    "\n",
    "lgbBO = BayesianOptimization(\n",
    "    func_fixed,\n",
    "    {   'num_leaves': (16, 1024),  # num_leaves,       범위(16~1024)\n",
    "        'learning_rate': (0.0001, 0.1),  # learning_rate,    범위(0.0001~0.1)\n",
    "        'n_estimators': (16, 1024),  # n_estimators,     범위(16~1024)\n",
    "        'subsample': (0, 1),  # subsample,        범위(0~1)\n",
    "        'colsample_bytree': (0, 1),  # colsample_bytree, 범위(0~1)\n",
    "        'reg_alpha': (0, 10),  # reg_alpha,        범위(0~10)\n",
    "        'reg_lambda': (0, 50),  # reg_lambda,       범위(0~50)\n",
    "        \"bagging_fraction\": (0, 1)\n",
    "    },\n",
    "    random_state = 21  # 시드 고정\n",
    ")\n",
    "\n",
    "lgbBO.maximize(init_points = 5, n_iter = 30)  # 처음 5회 랜덤 값으로 score 계산 후 50회 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = lgbBO.max['params']\n",
    "models = lgb_cv(\n",
    "    params['num_leaves'],\n",
    "    params['learning_rate'],\n",
    "    params['n_estimators'],\n",
    "    params['subsample'],\n",
    "    params['colsample_bytree'],\n",
    "    params['reg_alpha'],\n",
    "    params['reg_lambda'],\n",
    "    params[\"bagging_fraction\"],\n",
    "    x_data = x_train, y_data = y_train, n_splits = 5, output = 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_test = pd.read_csv(\"/Users/gimjiseong/Downloads/[ DACON ] Game_Behavior_DataAnalysis_Comp./tidy_test.csv\")\n",
    "x_test = tidy_test.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.set_index(\"game_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for model in models:\n",
    "    pred = model.predict_proba(x_test)[:, 1]\n",
    "    preds.append(pred)\n",
    "pred = np.mean(preds, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>38872</td>\n",
       "      <td>0.664486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38873</td>\n",
       "      <td>0.643187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38874</td>\n",
       "      <td>0.509320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38875</td>\n",
       "      <td>0.223850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38876</td>\n",
       "      <td>0.591681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38877</td>\n",
       "      <td>0.472641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38878</td>\n",
       "      <td>0.757168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38879</td>\n",
       "      <td>0.391858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38880</td>\n",
       "      <td>0.441628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38881</td>\n",
       "      <td>0.444267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38882</td>\n",
       "      <td>0.639325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38883</td>\n",
       "      <td>0.374654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38884</td>\n",
       "      <td>0.451711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38885</td>\n",
       "      <td>0.845664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38886</td>\n",
       "      <td>0.575701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38887</td>\n",
       "      <td>0.626429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38888</td>\n",
       "      <td>0.253530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38889</td>\n",
       "      <td>0.696539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38890</td>\n",
       "      <td>0.639703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38891</td>\n",
       "      <td>0.532112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           winner\n",
       "game_id          \n",
       "38872    0.664486\n",
       "38873    0.643187\n",
       "38874    0.509320\n",
       "38875    0.223850\n",
       "38876    0.591681\n",
       "38877    0.472641\n",
       "38878    0.757168\n",
       "38879    0.391858\n",
       "38880    0.441628\n",
       "38881    0.444267\n",
       "38882    0.639325\n",
       "38883    0.374654\n",
       "38884    0.451711\n",
       "38885    0.845664\n",
       "38886    0.575701\n",
       "38887    0.626429\n",
       "38888    0.253530\n",
       "38889    0.696539\n",
       "38890    0.639703\n",
       "38891    0.532112"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================================================== [ output ] ===========================================================\n",
    "submission = pd.read_csv('/Users/gimjiseong/Downloads/[ DACON ] Game_Behavior_DataAnalysis_Comp./data/sample_submission.csv', index_col = 0)\n",
    "submission['winner'] = submission['winner'] + pred\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('/Users/gimjiseong/Downloads/[ DACON ] Game_Behavior_DataAnalysis_Comp./output14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
